/* Backend with OpenAI and Groq API integration */

const express = require("express");
const cors = require("cors");
require("dotenv").config();

// === OpenAI SDK ===
const OpenAI = require("openai");

// === Groq SDK ===
const Groq = require("groq-sdk");

const app = express();
app.use(cors());
app.use(express.json());

// -------------------
// OpenAI Client
// -------------------
const openaiClient = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Groq Client
const groqClient = new Groq({
  apiKey: process.env.GROQ_API_KEY,
});

// -------------------
// Test route
// -------------------
app.get("/", (req, res) => {
  res.send("Backend running âœ…");
});

// -------------------
// OpenAI chat endpoint
// -------------------
app.post("/api/openai-chat", async (req, res) => {
  const userMessage = req.body?.message || "";

  if (!userMessage) {
    return res.json({ reply: "Nem kaptam Ã¼zenetet a kÃ©rÃ©sben." });
  }

  try {
    const openaiResponse = await openaiClient.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content:
            "Te egy barÃ¡tsÃ¡gos magyar AI tutor vagy, aki rÃ¶viden, Ã©rthetÅ‘en magyarÃ¡z.",
        },
        {
          role: "user",
          content: userMessage,
        },
      ],
    });

    const reply =
      openaiResponse.choices?.[0]?.message?.content?.trim() ||
      "Ãœres vÃ¡lasz Ã©rkezett a modeltÅ‘l. ðŸ˜…";

    console.log("OpenAI reply:", reply);
    return res.json({ reply });
  } catch (err) {
    console.error("OpenAI error:", err?.response?.data || err.message);
    return res.json({
      reply:
        "âš ï¸ Hiba tÃ¶rtÃ©nt az OpenAI hÃ­vÃ¡s kÃ¶zben. (RÃ©szletek a szerver logban.)",
    });
  }
});

// -------------------
// Groq chat endpoint
// -------------------
app.post("/api/groq-chat", async (req, res) => {
  const userMessage = req.body?.message || "";

  if (!userMessage) {
    return res.json({ reply: "Nem kaptam Ã¼zenetet a kÃ©rÃ©sben." });
  }

  try {
    const groqResponse = await groqClient.chat.completions.create({
      model: "llama-3.3-70b-versatile",
      messages: [
        {
          role: "system",
          content:
            "Te egy barÃ¡tsÃ¡gos Ã©s Ã©rthetÅ‘ magyar AI tutor vagy, mindig segÃ­tÅ‘kÃ©sz vagy, de mindig visszaterled a tÃ©mÃ¡t a tanulÃ¡sra.",
        },
        {
          role: "user",
          content: userMessage,
        },
      ],
    });

    const reply =
      groqResponse.choices?.[0]?.message?.content ||
      "Ãœres vÃ¡lasz Ã©rkezett a Groq modelltÅ‘l.";

    console.log("Groq reply:", reply);
    return res.json({ reply });
  } catch (err) {
    console.error("Groq API error:", err.message);
    return res.json({
      reply:
        "âš ï¸ Hiba tÃ¶rtÃ©nt a Groq AI hÃ­vÃ¡s kÃ¶zben. (RÃ©szletek a szerver konzolon.)",
    });
  }
});

// -------------------
// Start server
// -------------------
const SERVER_PORT = 4000;
app.listen(SERVER_PORT, () => {
  console.log(`Backend running on http://localhost:${SERVER_PORT}`);
});